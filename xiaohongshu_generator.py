#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å°çº¢ä¹¦çˆ†æ–‡ç”Ÿæˆå™¨ - æµ·å¤–æ•™è‚²+AIä¸“é¢˜
ä»ç½‘ç»œçƒ­ç‚¹è¯é¢˜ç”Ÿæˆå°çº¢ä¹¦çˆ†æ¬¾å†…å®¹
"""
import os
import sys
import re
from datetime import datetime
from topic_tracker import TopicTracker

# è®¾ç½®æ ‡å‡†è¾“å‡ºç¼–ç ä¸ºUTF-8
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))


class XiaohongshuGenerator:
    """å°çº¢ä¹¦çˆ†æ–‡ç”Ÿæˆå™¨ - æµ·å¤–æ•™è‚²AIä¸“é¢˜"""

    # æµ·å¤–æ•™è‚²+AIå…³é”®è¯åº“
    PARENT_KEYWORDS = {
        'AIå˜é©': [
            'AIæ•™è‚²', 'ChatGPT', 'OpenAI', 'AIè€å¸ˆ', 'AIè¾…åŠ©æ•™å­¦',
            'æ™ºèƒ½æ•™è‚²', 'æ•™è‚²ç§‘æŠ€', 'EdTech', 'äººå·¥æ™ºèƒ½æ•™è‚²',
            'AIæ”¹å˜æ•™è‚²', 'æ•™è‚²AIåŒ–', 'AIé©å‘½', 'æŠ€æœ¯å˜é©',
            'æœºå™¨å­¦ä¹ æ•™è‚²', 'AIè¯¾å ‚', 'æ™ºèƒ½tutor',
            # è‹±æ–‡å…³é”®è¯
            'AI', 'artificial intelligence', 'machine learning', 'AI agent',
            'LLM', 'GPT', 'language model', 'deep learning',
            'AI generated', 'AI music', 'AI writing', 'AI code'
        ],
        'ç¼–ç¨‹æ•™è‚²': [
            'ç¼–ç¨‹æ•™è‚²', 'ç¼–ç¨‹å­¦ä¹ ', 'å°‘å„¿ç¼–ç¨‹', 'å­¦ç¼–ç¨‹',
            'programming', 'code', 'coding', 'developer',
            'JavaScript', 'Python', 'ç¼–ç¨‹æ€ç»´', 'computational',
            'software', 'engineering', 'ç¨‹åºå‘˜', 'å¼€å‘è€…'
        ],
        'å†™ä½œè¡¨è¾¾': [
            'å†™ä½œèƒ½åŠ›', 'è¡¨è¾¾èƒ½åŠ›', 'å†™ä½œ', 'æ²Ÿé€š',
            'writing', 'communication', 'language', 'Markdown',
            'æŠ€æœ¯å†™ä½œ', 'è¡¨è¾¾', 'æ¼”è®²', 'debate',
            'natural language', 'interface', 'prompt'
        ],
        'ç½‘ç»œå®‰å…¨': [
            'ç½‘ç»œå®‰å…¨', 'ä¿¡æ¯å®‰å…¨', 'æ•°æ®å®‰å…¨', 'éšç§ä¿æŠ¤',
            'security', 'privacy', 'password', 'encryption',
            'hacking', 'vulnerability', 'data breach', 'å®‰å…¨'
        ],
        'å­¦ä¹ æ–¹å¼': [
            'ä¸ªæ€§åŒ–å­¦ä¹ ', 'è‡ªé€‚åº”å­¦ä¹ ', 'åœ¨çº¿å­¦ä¹ ', 'æ··åˆå­¦ä¹ ',
            'ç¿»è½¬è¯¾å ‚', 'é¡¹ç›®åˆ¶å­¦ä¹ ', 'PBL', 'æ¢ç©¶å¼å­¦ä¹ ',
            'å­¦ä¹ æ•ˆç‡', 'å­¦ä¹ å·¥å…·', 'å­¦ä¹ å¹³å°', 'æ•™è‚²APP',
            'è‡ªä¸»å­¦ä¹ ', 'ç»ˆèº«å­¦ä¹ ', 'æŠ€èƒ½åŸ¹å…»',
            'learning', 'education', 'tutorial', 'course'
        ],
        'æ•™è‚²è¶‹åŠ¿': [
            'æ•™è‚²', 'å­¦æ ¡', 'è€å¸ˆ', 'å­¦ç”Ÿ',
            'education', 'school', 'teacher', 'student',
            'university', 'college', 'learning', 'teaching'
        ]
    }

    # çˆ†æ¬¾æ ‡é¢˜æ¨¡æ¿ - ä¸“é—¨é’ˆå¯¹æµ·å¤–æ•™è‚²+AI
    TITLE_TEMPLATES = {
        'éœ‡æ’¼å‹': [
            "ğŸ˜± ç¾å›½å­¦æ ¡ç‚¸é”…äº†ï¼ChatGPTå¼ºåˆ¶ä¸‹æ¶ï¼Œæ ¡é•¿è¿™æ ·è¯´...",
            "ğŸ’” 90%çš„å®¶é•¿è¿˜ä¸çŸ¥é“ï¼AIå·²ç»æ‚„æ‚„æ”¹å˜äº†ç¾å›½æ•™è‚²",
            "âš ï¸ ç´§æ€¥ï¼å¸¸æ˜¥è—¤åæ ¡æœ€æ–°æ”¿ç­–ï¼šChatGPTå°†è¢«...",
            "âŒ åˆ«å†ç³Šæ¶‚äº†ï¼å…³äºAIæ•™è‚²ï¼Œç¾å›½è€å¸ˆçš„çœŸå¿ƒè¯",
            "ğŸš¨ éœ‡æ’¼æ•™è‚²éƒ¨ï¼è¿™æ‰€å­¦æ ¡å…¨é¢ç¦ç”¨AIï¼Œç»“æœ..."
        ],
        'å¯¹æ¯”å‹': [
            "ğŸ¤” ä¸ºä»€ä¹ˆç¾å›½å­©å­éƒ½åœ¨ç”¨AIå­¦æ•°å­¦ï¼Œæˆ‘ä»¬è¿˜åœ¨...",
            "ğŸ˜± åŒæ ·çš„AIå·¥å…·ï¼Œä¸­ç¾æ•™è‚²å·®è·ç«Ÿç„¶è¿™ä¹ˆå¤§ï¼",
            "ğŸ’¡ çœ‹çœ‹èŠ¬å…°æ€ä¹ˆåšçš„ï¼AIæ—¶ä»£çš„æ•™è‚²æ”¹é©",
            "âŒ ä¼ ç»Ÿæ•™è‚² VS AIæ•™è‚²ï¼Œ20å¹´åå·®è·ä»¤äººçª’æ¯",
            "ğŸ”„ è¿™æ³¢AIé©å‘½ï¼Œä¸ºä»€ä¹ˆç¾å›½å­¦æ ¡èµ°åœ¨äº†å‰é¢ï¼Ÿ"
        ],
        'æ•°æ®å‹': [
            "ğŸ“Š æ•°æ®è¯´è¯ï¼šä½¿ç”¨AIçš„å­©å­ï¼Œæˆç»©æå‡äº†200%ï¼",
            "ğŸ” æœ€æ–°ç ”ç©¶ï¼šç¾å›½85%çš„å­¦æ ¡å·²å¼•å…¥AIæ•™å­¦",
            "ğŸ’¡ å“ˆä½›æŠ¥å‘Šï¼šAIæ—¶ä»£ï¼Œè¿™5ç§èƒ½åŠ›æ¯”æˆç»©æ›´é‡è¦",
            "ğŸ“ˆ æŠ•èµ„1ä¸‡å…ƒVSå…è´¹AIï¼Œæ•™è‚²å›æŠ¥ç‡å¯¹æ¯”",
            "ğŸ¯ è°ƒæŸ¥1000ä½ç¾å›½å¦ˆå¦ˆï¼šå¥¹ä»¬è¿™æ ·åº”å¯¹AIæ•™è‚²"
        ],
        'æ–¹æ³•å‹': [
            "âœ¨ å®è—ï¼ç¾å›½åæ ¡éƒ½åœ¨ç”¨çš„AIå­¦ä¹ æ³•",
            "ğŸ“š å»ºè®®æ”¶è—ï¼æˆ‘å’Œå­©å­è¿™æ ·ç”¨ChatGPTå­¦è‹±è¯­",
            "ğŸ’ª äº²æµ‹æœ‰æ•ˆï¼ç¾å›½å¦ˆå¦ˆçš„AIæ•™è‚²å¿ƒå¾—",
            "ğŸ¯ ä¸èŠ±ä¸€åˆ†é’±ï¼Œå¤åˆ»ç¾å›½AIè¯¾å ‚çš„3ä¸ªæ–¹æ³•",
            "ğŸŒŸ æ–¯å¦ç¦æ•™æˆæ¨èï¼šAIæ—¶ä»£è¿™æ ·åŸ¹å…»å­©å­"
        ],
        'ç„¦è™‘å…±é¸£å‹': [
            "ğŸ˜­ çœ‹å®Œç¾å›½æ•™è‚²ç°çŠ¶ï¼Œæˆ‘å¤±çœ äº†",
            "ğŸ’ª è¿™æ‰å«æ•™è‚²ï¼çœ‹å®Œå·®è·æˆ‘å“­äº†",
            "â¤ï¸ è½¬å‘ç»™ç„¦è™‘çš„å®¶é•¿ï¼šAIæ—¶ä»£æˆ‘ä»¬è¦è¿™æ ·å‡†å¤‡",
            "ğŸ™ åˆ«è®©å­©å­è¾“åœ¨AIæ—¶ä»£ï¼Œè¿™ç¯‡ä¸€å®šè¦çœ‹",
            "ğŸ˜Œ ç»ˆäºæ‰¾åˆ°ç­”æ¡ˆäº†ï¼Œå…³äºå­©å­æœªæ¥çš„æ€è€ƒ"
        ],
        'å‰ç»å‹': [
            "ğŸ”® 2030å¹´çš„æ•™è‚²ä¼šæ€æ ·ï¼Ÿç¾å›½æ ¡é•¿å‘Šè¯‰ä½ ",
            "ğŸ’« AIæ¥äº†ï¼Œå­©å­éœ€è¦æŒæ¡çš„3ç§æ ¸å¿ƒèƒ½åŠ›",
            "ğŸš€ æœªæ¥10å¹´ï¼Œè¿™äº›å­©å­æœ€æœ‰ç«äº‰åŠ›",
            "âš¡ æ•™è‚²é©å‘½å·²æ¥ï¼Œä½ è¿˜åœ¨ç”¨è€æ–¹æ³•å—ï¼Ÿ",
            "ğŸŒŸ æå‰å¸ƒå±€ï¼AIæ—¶ä»£çš„èµ¢å®¶æ•™è‚²æ³•"
        ]
    }

    # çƒ­é—¨emoji
    EMOJIS = ['ğŸ”¥', 'âš ï¸', 'âœ¨', 'ğŸ’¡', 'â¤ï¸', 'ğŸ˜±', 'ğŸ’”', 'ğŸ˜­', 'ğŸ™', 'ğŸ“Š',
              'ğŸš¨', 'âš¡', 'ğŸŒŸ', 'ğŸ’', 'ğŸ“', 'ğŸ‡ºğŸ‡¸', 'ğŸŒ', 'ğŸ¤–', 'ğŸ’»', 'ğŸ¯']

    # å°çº¢ä¹¦çƒ­é—¨æ ‡ç­¾
    HASHTAGS = [
        '#AIæ•™è‚²', '#ChatGPTæ•™è‚²', '#æµ·å¤–æ•™è‚²', '#ç¾å›½æ•™è‚²',
        '#æ•™è‚²ç§‘æŠ€', '#æœªæ¥æ•™è‚²', '#å­¦ä¹ æ–¹æ³•', '#è‚²å„¿å¿ƒå¾—',
        '#æ•™è‚²ç„¦è™‘', '#AIæ—¶ä»£', '#æ•™è‚²å˜é©', '#å›½é™…æ•™è‚²',
        '#ç•™å­¦æ•™è‚²', '#ç´ è´¨æ•™è‚²', '#äº²å­æ•™è‚²', '#å¹²è´§åˆ†äº«',
        '#ç¾å›½å­¦æ ¡', '#æ•™è‚²åˆ›æ–°', '#å­¦ä¹ å·¥å…·', '#çˆ¶æ¯å¿…çœ‹'
    ]

    def __init__(self):
        self.topics = []

    def load_topics_from_file(self, filepath):
        """ä»æŠ¥å‘Šæ–‡ä»¶åŠ è½½è¯é¢˜"""
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                content = f.read()

            # è§£æè¯é¢˜
            self.topics = self._parse_topics(content)
            print(f"âœ“ æˆåŠŸåŠ è½½ {len(self.topics)} æ¡è¯é¢˜")
            return True
        except Exception as e:
            print(f"âœ— åŠ è½½è¯é¢˜å¤±è´¥: {e}")
            return False

    def _parse_topics(self, content):
        """ä»Markdownå†…å®¹è§£æè¯é¢˜"""
        topics = []
        lines = content.split('\n')

        current_platform = None
        for line in lines:
            # æ£€æµ‹å¹³å°
            if line.startswith('## ğŸ“±'):
                current_platform = line.replace('## ğŸ“±', '').strip()
            # æ£€æµ‹è¯é¢˜
            elif line.startswith('### '):
                title = line.replace('###', '').strip()
                # æå–æ’åå’Œæ ‡é¢˜
                parts = title.split('. ', 1)
                if len(parts) == 2:
                    rank = parts[0]
                    title = parts[1].split('[')[0].strip()
                else:
                    title = title.strip()

                topics.append({
                    'platform': current_platform or 'Unknown',
                    'title': title,
                    'original': title
                })

        return topics

    def filter_parenting_topics(self):
        """ç­›é€‰æ•™è‚²+AIè¯é¢˜"""
        filtered = []

        for topic in self.topics:
            title_lower = topic['title'].lower()

            # æ£€æŸ¥æ˜¯å¦åŒ…å«ç›¸å…³å…³é”®è¯
            for category, keywords in self.PARENT_KEYWORDS.items():
                for keyword in keywords:
                    if keyword.lower() in title_lower:
                        filtered.append({
                            **topic,
                            'category': category,
                            'keyword': keyword
                        })
                        break

        print(f"âœ“ ç­›é€‰å‡º {len(filtered)} æ¡æ•™è‚²+AIè¯é¢˜")
        return filtered

    def generate_titles(self, topic, count=10):
        """ä¸ºè¯é¢˜ç”Ÿæˆçˆ†æ¬¾æ ‡é¢˜"""
        titles = []
        title = topic['title']

        # æå–å…³é”®ä¿¡æ¯
        key_info = self._extract_key_info(title)

        # ä»ä¸åŒæ¨¡æ¿ç”Ÿæˆæ ‡é¢˜
        for template_type, templates in self.TITLE_TEMPLATES.items():
            for template in templates[:2]:
                new_title = template

                # æ›¿æ¢å ä½ç¬¦
                if '{}' in new_title:
                    new_title = new_title.format(key_info)
                else:
                    if not new_title.endswith('...'):
                        new_title = new_title + ' - ' + key_info[:20]

                # æ·»åŠ emoji
                if not any(emoji in new_title for emoji in self.EMOJIS):
                    import random
                    emoji = random.choice(['ğŸ”¥', 'âš ï¸', 'âœ¨'])
                    new_title = emoji + ' ' + new_title

                titles.append({
                    'type': template_type,
                    'title': new_title.strip()
                })

                if len(titles) >= count:
                    return titles

        return titles[:count]

    def _extract_key_info(self, title):
        """æå–æ ‡é¢˜å…³é”®ä¿¡æ¯"""
        for emoji in self.EMOJIS:
            title = title.replace(emoji, '')

        words = title.split()
        if len(words) > 8:
            key_info = ' '.join(words[:8]) + '...'
        else:
            key_info = title

        return key_info[:35]

    def _is_english(self, text):
        """æ£€æµ‹æ–‡æœ¬æ˜¯å¦ä¸»è¦ä¸ºè‹±æ–‡"""
        # ç§»é™¤emojiå’Œç‰¹æ®Šå­—ç¬¦
        text = re.sub(r'[^\w\s]', '', text)
        if not text:
            return False
        # è®¡ç®—è‹±æ–‡å­—ç¬¦æ¯”ä¾‹
        english_chars = sum(1 for c in text if c.isalpha() and ord(c) < 128)
        total_chars = sum(1 for c in text if c.isalpha())
        if total_chars == 0:
            return False
        return english_chars / total_chars > 0.6

    def _translate_title(self, title):
        """ç¿»è¯‘è‹±æ–‡æ ‡é¢˜ä¸ºä¸­æ–‡ï¼ˆä¿ç•™åŸæ ‡é¢˜ï¼Œæ·»åŠ ä¸­æ–‡è¯´æ˜ï¼‰"""
        if not self._is_english(title):
            return title

        # å¸¸è§æŠ€æœ¯æœ¯è¯­ç¿»è¯‘å­—å…¸
        translations = {
            # AIç›¸å…³
            'AI': 'AI',
            'LLM': 'å¤§è¯­è¨€æ¨¡å‹',
            'LLMs': 'å¤§è¯­è¨€æ¨¡å‹',
            'GPT': 'GPT',
            'ChatGPT': 'ChatGPT',
            'OpenAI': 'OpenAI',
            'DeepSeek': 'DeepSeek',
            'Claude': 'Claude',
            'Gemini': 'Gemini',
            'machine learning': 'æœºå™¨å­¦ä¹ ',
            'deep learning': 'æ·±åº¦å­¦ä¹ ',
            'neural network': 'ç¥ç»ç½‘ç»œ',
            'language model': 'è¯­è¨€æ¨¡å‹',
            'artificial intelligence': 'äººå·¥æ™ºèƒ½',

            # ç¼–ç¨‹ç›¸å…³
            'programming': 'ç¼–ç¨‹',
            'code': 'ä»£ç ',
            'coding': 'ç¼–ç¨‹',
            'software': 'è½¯ä»¶',
            'developer': 'å¼€å‘è€…',
            'engineering': 'å·¥ç¨‹',
            'JavaScript': 'JavaScript',
            'Python': 'Python',
            'Rust': 'Rust',
            'Java': 'Java',
            'API': 'API',
            'framework': 'æ¡†æ¶',
            'library': 'åº“',

            # æ•™è‚²ç›¸å…³
            'education': 'æ•™è‚²',
            'learning': 'å­¦ä¹ ',
            'tutorial': 'æ•™ç¨‹',
            'course': 'è¯¾ç¨‹',
            'teacher': 'è€å¸ˆ',
            'student': 'å­¦ç”Ÿ',
            'school': 'å­¦æ ¡',
            'university': 'å¤§å­¦',
            'college': 'å­¦é™¢',

            # ç½‘ç»œç›¸å…³
            'security': 'å®‰å…¨',
            'privacy': 'éšç§',
            'hacking': 'é»‘å®¢',
            'vulnerability': 'æ¼æ´',
            'password': 'å¯†ç ',
            'encryption': 'åŠ å¯†',
            'data breach': 'æ•°æ®æ³„éœ²',

            # å·¥å…·ç›¸å…³
            'tool': 'å·¥å…·',
            'platform': 'å¹³å°',
            'system': 'ç³»ç»Ÿ',
            'application': 'åº”ç”¨',
            'app': 'åº”ç”¨',
            'service': 'æœåŠ¡',
            'feature': 'åŠŸèƒ½',

            # é€šç”¨è¯æ±‡
            'how to': 'å¦‚ä½•',
            'guide': 'æŒ‡å—',
            'best': 'æœ€ä½³',
            'top': 'é¡¶çº§',
            'vs': 'å¯¹å†³',
            'versus': 'å¯¹å†³',
            'why': 'ä¸ºä»€ä¹ˆ',
            'what': 'ä»€ä¹ˆ',
            'how': 'å¦‚ä½•',
            'tips': 'æŠ€å·§',
            'tricks': 'æŠ€å·§',
            'secrets': 'ç§˜å¯†',
            'introduction': 'ä»‹ç»',
            'overview': 'æ¦‚è¿°',
            'analysis': 'åˆ†æ',
            'review': 'è¯„æµ‹',
            'comparison': 'å¯¹æ¯”',
        }

        # ç”Ÿæˆä¸­æ–‡è¯´æ˜
        chinese_desc = ""

        # å°è¯•æå–å…³é”®è¯å¹¶ç”Ÿæˆè¯´æ˜
        title_upper = title.upper()
        title_lower = title.lower()

        # AIç›¸å…³
        if 'LLM' in title_upper or 'GPT' in title_upper or 'Claude' in title or 'Gemini' in title or 'OpenAI' in title:
            if any(word in title_lower for word in ['education', 'learning', 'teaching', 'school']):
                chinese_desc = "AIå¦‚ä½•æ”¹å˜æ•™è‚²"
            elif any(word in title_lower for word in ['future', 'impact', 'revolution', 'transform']):
                chinese_desc = "AIå¯¹æœªæ¥çš„å½±å“"
            else:
                chinese_desc = "å…³äºå¤§è¯­è¨€æ¨¡å‹çš„çƒ­è®®"
        elif 'AI' in title_upper or 'artificial intelligence' in title_lower:
            if any(word in title_lower for word in ['education', 'learning', 'teaching']):
                chinese_desc = "AIåœ¨æ•™è‚²ä¸­çš„åº”ç”¨"
            elif any(word in title_lower for word in ['ethics', 'safety', 'risk', 'danger']):
                chinese_desc = "AIçš„ä¼¦ç†ä¸å®‰å…¨"
            else:
                chinese_desc = "å…³äºäººå·¥æ™ºèƒ½çš„è®¨è®º"

        # ç¼–ç¨‹ç›¸å…³
        elif any(word in title_lower for word in ['programming', 'code', 'coding', 'developer', 'software']):
            if any(word in title_lower for word in ['education', 'learning', 'tutorial', 'beginner']):
                chinese_desc = "ç¼–ç¨‹æ•™è‚²è¯é¢˜"
            elif any(word in title_lower for word in ['language', 'javascript', 'python', 'rust', 'java']):
                chinese_desc = "ç¼–ç¨‹è¯­è¨€è®¨è®º"
            else:
                chinese_desc = "è½¯ä»¶å¼€å‘ç›¸å…³"

        # å®‰å…¨ç›¸å…³
        elif any(word in title_lower for word in ['security', 'privacy', 'hacking', 'vulnerability', 'password']):
            chinese_desc = "ç½‘ç»œå®‰å…¨è¯é¢˜"

        # æ•™è‚²/å­¦ä¹ ç›¸å…³
        elif any(word in title_lower for word in ['education', 'learning', 'school', 'university', 'college']):
            if any(word in title_lower for word in ['online', 'remote', 'digital']):
                chinese_desc = "åœ¨çº¿æ•™è‚²è¯é¢˜"
            else:
                chinese_desc = "æ•™è‚²åˆ›æ–°è®¨è®º"

        # å·¥å…·/å¹³å°ç›¸å…³
        elif any(word in title_lower for word in ['tool', 'platform', 'system', 'application', 'app']):
            chinese_desc = "å®ç”¨å·¥å…·æ¨è"

        # é€šç”¨æŠ€æœ¯è®¨è®º
        elif any(word in title_lower for word in ['technology', 'tech', 'digital', 'innovation']):
            chinese_desc = "ç§‘æŠ€å‰æ²¿è®¨è®º"

        # å¦‚æœæ— æ³•è¯†åˆ«ï¼Œä½¿ç”¨é€šç”¨è¯´æ˜
        else:
            chinese_desc = "æµ·å¤–ç§‘æŠ€çƒ­ç‚¹"

        # ç»„åˆç»“æœï¼šä¿ç•™è‹±æ–‡åŸæ ‡é¢˜ + æ·»åŠ ä¸­æ–‡è¯´æ˜
        if len(title) > 50:
            # æ ‡é¢˜å¤ªé•¿ï¼Œæˆªæ–­
            title_short = title[:47] + "..."
            return f"{title_short}\nï¼ˆ{chinese_desc}ï¼‰"
        else:
            return f"{title}\nï¼ˆ{chinese_desc}ï¼‰"

    def generate_content(self, topic):
        """ç”Ÿæˆå°çº¢ä¹¦å†…å®¹"""
        category = topic.get('category', '')
        keyword = topic.get('keyword', '')
        title = topic['title']

        # æ ¹æ®åˆ†ç±»ç”Ÿæˆå†…å®¹
        if 'AIå˜é©' in category or 'AI' in keyword:
            return self._generate_ai_revolution_content(topic)
        elif 'æµ·å¤–' in category or 'ç¾å›½' in keyword or 'æ¬§æ´²' in keyword:
            return self._generate_overseas_content(topic)
        elif 'äº‰è®®' in category:
            return self._generate_controversy_content(topic)
        elif 'ç„¦è™‘' in category:
            return self._generate_anxiety_content(topic)
        else:
            return self._generate_general_content(topic)

    def _generate_ai_revolution_content(self, topic):
        """ç”ŸæˆAIå˜é©å†…å®¹"""
        title = topic['title']
        translated_title = self._translate_title(title)

        content = f"""
ğŸ¤– AIçœŸçš„è¦é¢ è¦†æ•™è‚²äº†å—ï¼Ÿ

æœ€è¿‘çœ‹åˆ°è¿™ä¸ªæ¶ˆæ¯ï¼š
ã€{translated_title}ã€‘

è¯´å®è¯ï¼Œçœ‹å®Œæˆ‘çš„ç¬¬ä¸€ååº”æ˜¯ï¼š
ğŸ˜± æˆ‘ä»¬çš„å­©å­å‡†å¤‡å¥½è¿æ¥AIæ—¶ä»£äº†å—ï¼Ÿ

ğŸ‡ºğŸ‡¸ ç¾å›½å­¦æ ¡å·²ç»åœ¨è¡ŒåŠ¨ï¼š
âœ… 77%çš„å­¦åŒºå¼€å§‹è¯•ç‚¹AIæ•™å­¦
âœ… ChatGPTè¢«çº³å…¥éƒ¨åˆ†è¯¾ç¨‹
âœ… ä¸ªæ€§åŒ–AI tutoræ™®åŠ

ğŸ’¡ ä¸ºä»€ä¹ˆä»–ä»¬è¿™ä¹ˆåšï¼Ÿ

å› ä¸ºç¾å›½æ•™è‚²ç•Œè®¤è¯†åˆ°ï¼š
âŒ å°å µAIä¸æ˜¯åŠæ³•
âœ… æ•™ä¼šå­©å­æ­£ç¡®ä½¿ç”¨æ‰æ˜¯å…³é”®

ğŸ¯ æˆ‘ä»¬èƒ½å­¦åˆ°ä»€ä¹ˆï¼Ÿ

1ï¸âƒ£ ä¸è¦æŠŠAIå½“æ´ªæ°´çŒ›å…½
   å®ƒæ˜¯å·¥å…·ï¼Œå…³é”®æ˜¯æ€ä¹ˆç”¨

2ï¸âƒ£ åŸ¹å…»AIæ€ç»´
   - æ‰¹åˆ¤æ€§æ€ç»´
   - ä¿¡æ¯é‰´åˆ«èƒ½åŠ›
   - äººæœºåä½œèƒ½åŠ›

3ï¸âƒ£ å…³æ³¨è½¯æŠ€èƒ½
   - åˆ›é€ åŠ›ï¼ˆAIä¸ä¼šï¼‰
   - æƒ…å•†ï¼ˆæ›´é‡è¦äº†ï¼‰
   - é€‚åº”æ€§ï¼ˆå¿«é€Ÿå­¦ä¹ ï¼‰

ğŸ’ª æœªæ¥çš„ç«äº‰
ä¸æ˜¯äººå’ŒAIçš„ç«äº‰
è€Œæ˜¯ä¼šç”¨AIçš„äºº vs ä¸ä¼šç”¨AIçš„äºº

â¤ï¸ è§‰å¾—æœ‰ç”¨è¯·ç‚¹èµæ”¶è—
è½¬å‘ç»™æ›´å¤šå®¶é•¿çœ‹åˆ°ğŸ’•

{self._get_random_hashtags()}

ğŸ‘‡ è¯„è®ºåŒºï¼šä½ ä¼šè®©å­©å­ç”¨AIå­¦ä¹ å—ï¼Ÿ
        """.strip()

        return content

    def _generate_overseas_content(self, topic):
        """ç”Ÿæˆæµ·å¤–æ•™è‚²å®è·µå†…å®¹"""
        title = topic['title']
        translated_title = self._translate_title(title)

        content = f"""
ğŸŒ çœ‹çœ‹æµ·å¤–æ˜¯æ€ä¹ˆåº”å¯¹AIæ•™è‚²çš„ï¼

ã€{translated_title}ã€‘

æœ€è¿‘ä¸€ç›´åœ¨ç ”ç©¶æµ·å¤–æ•™è‚²åŠ¨æ€
å‘ç°äº†ä¸€äº›å¾ˆæœ‰æ„æ€çš„å®è·µğŸ‘€

ğŸ‡ºğŸ‡¸ ç¾å›½çš„åšæ³•ï¼š
âœ… éƒ¨åˆ†å·å…è®¸å­¦ç”Ÿç”¨ChatGPTè¾…åŠ©å­¦ä¹ 
âœ… æ•™ä¼šå­¦ç”Ÿå¦‚ä½•é‰´åˆ«AIç”Ÿæˆçš„ä¿¡æ¯
âœ… æŠŠAIæ£€æµ‹å’Œè¯†åˆ«çº³å…¥è¯¾ç¨‹
âœ… é‡è§†prompt engineeringï¼ˆæç¤ºè¯å·¥ç¨‹ï¼‰

ğŸ‡«ğŸ‡· èŠ¬å…°çš„åˆ›æ–°ï¼š
âœ… AIè¾…åŠ©ä¸ªæ€§åŒ–å­¦ä¹ è·¯å¾„
âœ… å‡å°‘æœºæ¢°æ€§ä½œä¸šï¼Œå¢åŠ åˆ›é€ æ€§ä»»åŠ¡
âœ… æ•™å¸ˆè§’è‰²è½¬å˜ä¸ºå¼•å¯¼è€…

ğŸ‡¸ğŸ‡¬ æ–°åŠ å¡çš„å¹³è¡¡ï¼š
âœ… æ—¢ä¸ç¦æ­¢ä¹Ÿä¸é¼“åŠ±ï¼Œè§„èŒƒä½¿ç”¨
âœ… åˆ¶å®šAIä½¿ç”¨ä¼¦ç†å‡†åˆ™
âœ… é‡è§†ä¼ ç»ŸåŸºç¡€èƒ½åŠ›+AIæŠ€èƒ½

ğŸ’¡ ä»–ä»¬çš„å…±åŒç‚¹ï¼š
âŒ ä¸æ˜¯ç®€å•ç¦æ­¢æˆ–å¼€æ”¾
âœ… è€Œæ˜¯ç³»ç»Ÿæ€§åœ°åº”å¯¹

ğŸ¯ ç»™æˆ‘ä»¬çš„å¯å‘ï¼š

1ï¸âƒ£ æ•™è‚²è¦ä¸æ—¶ä¿±è¿›
   AIæ¥äº†ï¼Œæ•™è‚²æ–¹å¼å¿…é¡»æ”¹å˜

2ï¸âƒ£ åŸ¹å…»è¾¨åˆ«èƒ½åŠ›
   å­¦ä¼šåˆ¤æ–­ä¿¡æ¯çœŸä¼ªæ›´é‡è¦

3ï¸âƒ£ é‡è§†èƒ½åŠ›åŸ¹å…»
   è€Œä¸æ˜¯æ­»è®°ç¡¬èƒŒ

4ï¸âƒ£ æ•™å¸ˆéœ€è¦è½¬å‹
   ä»çŸ¥è¯†ä¼ æˆè€…åˆ°èƒ½åŠ›åŸ¹å…»è€…

ğŸ’ª æˆ‘ä»¬ä¸éœ€è¦ç…§æ¬
ä½†å¯ä»¥å€Ÿé‰´ä»–ä»¬çš„æ€è·¯

â¤ï¸ è§‰å¾—æœ‰ç”¨è¯·ç‚¹èµæ”¶è—
è½¬å‘ç»™æ›´å¤šå®¶é•¿ğŸ’•

{self._get_random_hashtags()}

ğŸ‘‡ ä½ æ”¯æŒå“ªç§æ•™è‚²æ–¹å¼ï¼Ÿ
        """.strip()

        return content

    def _generate_controversy_content(self, topic):
        """ç”Ÿæˆäº‰è®®å†²çªå†…å®¹"""
        title = topic['title']
        translated_title = self._translate_title(title)

        content = f"""
âš ï¸ ChatGPTè¿›å…¥æ ¡å›­ï¼Œæ•™è‚²ç•Œåµç¿»äº†ï¼

ã€{translated_title}ã€‘

æœ€è¿‘è¿™ä¸ªè¯é¢˜åœ¨å›½å¤–æ•™è‚²åœˆç‚¸é”…äº†ğŸ”¥

ğŸš« åå¯¹æ´¾è¯´ï¼š
âŒ è¿™æ˜¯ä½œå¼Šï¼ç ´åå­¦æœ¯è¯šä¿¡
âŒ å­¦ç”Ÿä¼šè¿‡åº¦ä¾èµ–AI
âŒ è€å¸ˆæ— æ³•åˆ¤æ–­å­¦ç”ŸçœŸå®æ°´å¹³
âŒ åŠ å‰§æ•™è‚²ä¸å…¬å¹³

âœ… æ”¯æŒæ´¾è¯´ï¼š
âœ… è¿™æ˜¯ç”Ÿäº§åŠ›å·¥å…·ï¼Œä¸ºä»€ä¹ˆè¦ç¦æ­¢ï¼Ÿ
âœ… å°±åƒå½“å¹´è®¡ç®—å™¨ä¸€æ ·
âœ… å…³é”®æ˜¯æ•™ä¼šå­¦ç”Ÿæ­£ç¡®ä½¿ç”¨
âœ… å¯ä»¥å¸®åŠ©è€å¸ˆå‡è½»è´Ÿæ‹…

ğŸ’” æˆ‘çš„æ€è€ƒï¼š

å…¶å®ä¸¤æ´¾éƒ½æœ‰é“ç†
ä½†å…³é”®é—®é¢˜å¯èƒ½æ˜¯ï¼š
ğŸ¯ æˆ‘ä»¬çš„æ•™è‚²ç›®æ ‡æ˜¯ä»€ä¹ˆï¼Ÿ

å¦‚æœç›®æ ‡æ˜¯ï¼š
âŒ æ­»è®°ç¡¬èƒŒ â†’ AIç¡®å®æœ‰å¨èƒ
âœ… åŸ¹å…»èƒ½åŠ› â†’ AIæ˜¯å¼ºå¤§çš„åŠ©æ‰‹

ğŸŒŸ ç¾å›½ä¸€äº›å­¦æ ¡çš„åšæ³•ï¼š

1ï¸âƒ£ æ˜ç¡®ä½¿ç”¨è§„èŒƒ
   ä»€ä¹ˆæ—¶å€™å¯ä»¥ç”¨ï¼Œä»€ä¹ˆæ—¶å€™ä¸è¡Œ

2ï¸âƒ£ é‡æ–°è®¾è®¡ä½œä¸š
   æ›´æ³¨é‡æ€è€ƒå’Œè¿‡ç¨‹
   è€Œä¸æ˜¯æ ‡å‡†ç­”æ¡ˆ

3ï¸âƒ£ æ•™ä¼šAIç´ å…»
   å¦‚ä½•æ­£ç¡®ä½¿ç”¨å·¥å…·
   å¦‚ä½•é‰´åˆ«ä¿¡æ¯çœŸä¼ª

ğŸ’ª æ—¶ä»£åœ¨å˜
æˆ‘ä»¬çš„æ•™è‚²ä¹Ÿå¿…é¡»æ”¹å˜

ç¦æ­¢ä¸æ˜¯åŠæ³•
å¼•å¯¼æ‰æ˜¯å…³é”®â¤ï¸

{self._get_random_hashtags()}

ğŸ‘‡ ä½ æ”¯æŒæ ¡å›­é‡Œä½¿ç”¨ChatGPTå—ï¼Ÿ
        """.strip()

        return content

    def _generate_anxiety_content(self, topic):
        """ç”Ÿæˆæ•™è‚²ç„¦è™‘å†…å®¹"""
        title = topic['title']
        translated_title = self._translate_title(title)

        content = f"""
ğŸ’” çœ‹å®Œè¿™ä¸ªï¼Œä½œä¸ºå®¶é•¿æˆ‘å½»å¤œéš¾çœ ...

ã€{translated_title}ã€‘

æœ€è¿‘AIæ•™è‚²çš„è¯é¢˜è¶Šæ¥è¶Šç«
æœ‹å‹åœˆé‡Œå…¨æ˜¯ï¼š
"ç¾å›½å­©å­éƒ½åœ¨ç”¨AIå­¦æ•°å­¦äº†"
"ä¸ä¼šç”¨AIçš„å­©å­ä¼šè¢«æ·˜æ±°"
...

è¯´å®è¯ï¼Œæˆ‘ä¹Ÿæœ‰ç‚¹æ…ŒğŸ˜°

ğŸ¤” æˆ‘ä»¬åœ¨ç„¦è™‘ä»€ä¹ˆï¼Ÿ

âŒ æ€•å­©å­è¾“åœ¨èµ·è·‘çº¿
âŒ æ€•è·Ÿä¸ä¸Šæ—¶ä»£
âŒ æ€•æœªæ¥çš„ç«äº‰
âŒ æ€•è‡ªå·±åšå¾—ä¸å¤Ÿ

ä½†æ˜¯...
å†·é™ä¸‹æ¥æƒ³æƒ³ï¼š
ğŸ“Š 85%çš„ç¾å›½å®¶é•¿ä¹Ÿåœ¨ç„¦è™‘åŒæ ·çš„é—®é¢˜

ğŸŒŸ ä¸€äº›æ€è€ƒï¼š

1ï¸âƒ£ AIæ˜¯å·¥å…·ï¼Œä¸æ˜¯ç›®æ ‡
   å­¦ä¼šä½¿ç”¨æ¯”æ‹¥æœ‰æ›´é‡è¦

2ï¸âƒ£ æ ¸å¿ƒèƒ½åŠ›ä¸ä¼šè¿‡æ—¶
   - æ‰¹åˆ¤æ€§æ€ç»´
   - åˆ›é€ åŠ›
   - æƒ…å•†å’Œæ²Ÿé€š
   è¿™äº›AIæ›¿ä»£ä¸äº†

3ï¸âƒ£ é€‚åˆå­©å­çš„æ‰æ˜¯æœ€å¥½çš„
   ä¸æ˜¯æ‰€æœ‰å­©å­éƒ½è¦å­¦ç¼–ç¨‹
   ä¸æ˜¯æ‰€æœ‰å­©å­éƒ½è¦ç”¨AI

ğŸ’¡ æˆ‘ç°åœ¨è¿™æ ·åšï¼š

âœ… äº†è§£AIä½†ä¸ç›²ä»
âœ… å…³æ³¨å­©å­çš„å…´è¶£å’Œç‰¹ç‚¹
âœ… åŸ¹å…»åº•å±‚èƒ½åŠ›è€Œä¸æ˜¯æŠ€èƒ½
âœ… ç»™å­©å­é€‰æ‹©çš„æƒåˆ©

ğŸ’ª è‚²å„¿è·¯ä¸Š
æˆ‘ä»¬éƒ½æ˜¯ç¬¬ä¸€æ¬¡
ä¸å¿…ç„¦è™‘ï¼Œä¸€èµ·æˆé•¿â¤ï¸

{self._get_random_hashtags()}

ğŸ‘‡ ä½ å¯¹AIæ•™è‚²ç„¦è™‘å—ï¼Ÿè¯„è®ºåŒºèŠèŠ
        """.strip()

        return content

    def _generate_general_content(self, topic):
        """ç”Ÿæˆé€šç”¨å†…å®¹"""
        title = topic['title']
        translated_title = self._translate_title(title)

        content = f"""
âœ¨ ä»Šå¤©çœ‹åˆ°ä¸€ä¸ªæ•™è‚²è¯é¢˜ï¼Œå¾ˆæœ‰æ„Ÿè§¦

ã€{translated_title}ã€‘

ä½œä¸ºçˆ¶æ¯
æˆ‘ä»¬æ€»æ˜¯åœ¨å­¦ä¹ 
åœ¨æˆé•¿çš„è·¯ä¸Š
å’Œå­©å­ä¸€èµ·è¿›æ­¥ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦

ğŸ’¡ æˆ‘çš„æ€è€ƒï¼š

AIæ—¶ä»£çš„æ•™è‚²
ç¡®å®å……æ»¡æŒ‘æˆ˜
ä½†ä¹Ÿå……æ»¡æœºä¼š

ğŸ“ ç»™å¤§å®¶çš„å°å»ºè®®ï¼š

1ï¸âƒ£ ä¿æŒå¼€æ”¾å¿ƒæ€
   æ–°æŠ€æœ¯ä¸å¯æ€•
   å¯æ€•çš„æ˜¯æ‹’ç»æ”¹å˜

2ï¸âƒ£ å…³æ³¨åº•å±‚èƒ½åŠ›
   - å­¦ä¹ èƒ½åŠ›
   - æ€è€ƒèƒ½åŠ›
   - åˆ›é€ èƒ½åŠ›
   è¿™äº›æ¯”çŸ¥è¯†æ›´é‡è¦

3ï¸âƒ£ é€‚åˆæœ€é‡è¦
   æ¯ä¸ªå­©å­ä¸åŒ
   æ‰¾åˆ°é€‚åˆçš„æ–¹å¼

4ï¸âƒ£ é™ªä¼´æ˜¯æœ€çè´µçš„
   å†å¥½çš„AIå·¥å…·
   ä¹Ÿæ›¿ä»£ä¸äº†çˆ¶æ¯çš„é™ªä¼´

ğŸ’ª æœªæ¥å±äº
ä¼šæ‹¥æŠ±å˜åŒ–çš„äºº

â¤ï¸ è‚²å„¿è·¯ä¸Š
ä¸€èµ·å­¦ä¹ ï¼Œä¸€èµ·æˆé•¿

{self._get_random_hashtags()}
        """.strip()

        return content

    def _get_random_hashtags(self):
        """è·å–éšæœºæ ‡ç­¾"""
        import random
        return ' '.join(random.sample(self.HASHTAGS, 8))

    def generate_xiaohongshu_post(self, topic, title_count=5):
        """ç”Ÿæˆå®Œæ•´çš„å°çº¢ä¹¦å¸–å­"""
        print(f"\n{'='*70}")
        print(f"ğŸ“ åŸè¯é¢˜: {topic['title']}")
        print(f"ğŸ“± æ¥æº: {topic['platform']}")
        print(f"ğŸ·ï¸ åˆ†ç±»: {topic.get('category', 'æœªçŸ¥')}")
        print(f"{'='*70}\n")

        # ç”Ÿæˆæ ‡é¢˜
        print("ğŸ¯ æ¨èæ ‡é¢˜ï¼ˆç‚¹å‡»ç‡ä¼˜åŒ–ç‰ˆï¼‰ï¼š\n")
        titles = self.generate_titles(topic, title_count)

        for i, t in enumerate(titles, 1):
            print(f"{i}. ã€{t['type']}ã€‘")
            print(f"   {t['title']}")
            print()

        # ç”Ÿæˆæ­£æ–‡
        print("\n" + "="*70)
        print("ğŸ“„ æ­£æ–‡å†…å®¹ï¼ˆå·²ä¼˜åŒ–äº’åŠ¨ï¼‰ï¼š\n")
        content = self.generate_content(topic)
        print(content)

        # ç”Ÿæˆå›¾ç‰‡/è§†é¢‘å»ºè®®
        image_suggestions = self._generate_image_suggestions(topic)

        # æ·»åŠ å»ºè®®
        print("\n" + "="*70)
        print("ğŸ’¡ å‘å¸ƒå»ºè®®ï¼š\n")
        print("âœ… æœ€ä½³å‘å¸ƒæ—¶é—´ï¼š")
        print("   å·¥ä½œæ—¥ï¼š7:00-9:00, 21:00-23:00")
        print("   å‘¨æœ«ï¼š9:00-11:00, 20:00-22:00")
        print()
        print("âœ… å°é¢å›¾å»ºè®®ï¼š")
        for suggestion in image_suggestions[:3]:
            print(f"   - {suggestion}")
        print()
        print("âœ… äº’åŠ¨æŠ€å·§ï¼š")
        print("   - æé—®ï¼š'ä½ å®¶å­©å­ç”¨è¿‡AIå­¦ä¹ å—ï¼Ÿ'")
        print("   - æŠ•ç¥¨ï¼š'æ”¯æŒæ ¡å›­ä½¿ç”¨ChatGPTå—ï¼Ÿ'")
        print("   - å¾é›†ï¼š'åˆ†äº«ä½ çš„AIæ•™è‚²ç»éªŒ'")
        print()

        return {
            'titles': titles,
            'content': content,
            'topic': topic,
            'image_suggestions': image_suggestions,
            'video_suggestions': self._generate_video_suggestions(topic)
        }

    def _generate_image_suggestions(self, topic):
        """ç”Ÿæˆé…å›¾å»ºè®®"""
        suggestions = [
            "å­©å­ä½¿ç”¨å¹³æ¿/ç”µè„‘å­¦ä¹ çš„ç…§ç‰‡ï¼ˆçœŸå®åœºæ™¯ï¼‰",
            "æ•™è‚²ç›¸å…³çš„å›¾ç‰‡ï¼ˆå­¦æ ¡ã€ä¹¦æœ¬ã€é»‘æ¿ç­‰ï¼‰",
            "æ·»åŠ é†’ç›®æ–‡å­—ï¼š'AIæ”¹å˜æ•™è‚²'ã€'ç¾å›½å­¦æ ¡'ç­‰",
            "å¯¹æ¯”å›¾ï¼šä¼ ç»Ÿå­¦ä¹  VS AIè¾…åŠ©å­¦ä¹ ",
            "æ•°æ®å›¾è¡¨ï¼šä½¿ç”¨Canvaåˆ¶ä½œæ•™è‚²ç›¸å…³æ•°æ®å¯è§†åŒ–",
            "emojiå›¾æ ‡ï¼šğŸ¤–ğŸ’¡ğŸ“šâœ¨ç­‰å¢å¼ºè§†è§‰æ•ˆæœ",
            "çº¢åº•ç™½å­—æˆ–é»„é»‘æ­é…çš„é†’ç›®æ ‡é¢˜å›¾"
        ]

        # æ ¹æ®åˆ†ç±»æ·»åŠ ç‰¹å®šå»ºè®®
        category = topic.get('category', '')
        if 'AI' in category:
            suggestions.append("AIæœºå™¨äººã€ChatGPTç•Œé¢æˆªå›¾")
            suggestions.append("æœªæ¥ç§‘æŠ€æ„Ÿçš„èƒŒæ™¯å›¾")
        elif 'æµ·å¤–' in category or 'ç¾å›½' in category:
            suggestions.append("ç¾å›½æ ¡å›­ã€æ•™å®¤ç…§ç‰‡")
            suggestions.append("å›½æ——emojiï¼šğŸ‡ºğŸ‡¸ğŸ‡«ğŸ‡®ğŸ‡¸ğŸ‡¬")

        return suggestions

    def _generate_video_suggestions(self, topic):
        """ç”Ÿæˆè§†é¢‘å»ºè®®"""
        return [
            "å½•åˆ¶å­©å­ä½¿ç”¨AIå·¥å…·å­¦ä¹ çš„çœŸå®åœºæ™¯ï¼ˆ15-30ç§’ï¼‰",
            "å¯¹æ¯”è§†é¢‘ï¼šä¼ ç»Ÿå­¦ä¹  VS AIè¾…åŠ©å­¦ä¹ çš„æ•ˆæœ",
            "è®¿è°ˆè§†é¢‘ï¼šå­©å­/å®¶é•¿å¯¹AIæ•™è‚²çš„çœ‹æ³•",
            "å±å¹•å½•åˆ¶ï¼šæ¼”ç¤ºå¦‚ä½•ä½¿ç”¨AIå­¦ä¹ å·¥å…·",
            "åŠ¨ç”»è§†é¢‘ï¼šè§£é‡ŠAIåœ¨æ•™è‚²ä¸­çš„åº”ç”¨",
            "æ•°æ®åŠ¨ç”»ï¼šå±•ç¤ºæ•™è‚²AIçš„å‘å±•è¶‹åŠ¿"
        ]


def main():
    """ä¸»å‡½æ•°"""
    print("="*70)
    print("ğŸ”¥ å°çº¢ä¹¦çˆ†æ–‡ç”Ÿæˆå™¨ - æµ·å¤–æ•™è‚²AIä¸“é¢˜")
    print("="*70)
    print()

    # åˆå§‹åŒ–ç”Ÿæˆå™¨
    generator = XiaohongshuGenerator()

    # åˆå§‹åŒ–è¯é¢˜è¿½è¸ªå™¨
    tracker = TopicTracker()
    tracker.print_stats()

    # æŸ¥æ‰¾æœ€æ–°çš„æŠ¥å‘Šæ–‡ä»¶
    import glob
    output_files = glob.glob('output/hot_topics_*.md')

    if not output_files:
        print("âŒ æœªæ‰¾åˆ°æŠ¥å‘Šæ–‡ä»¶")
        print("è¯·å…ˆè¿è¡Œä»¥ä¸‹å‘½ä»¤ç”Ÿæˆæ•°æ®ï¼š")
        print()
        print("docker run --rm -e USE_PROXY=true -e PROXY_HOST=host.docker.internal \\")
        print("  -e PROXY_PORT=10810 -e YOUTUBE_API_KEY='ä½ çš„å¯†é’¥' \\")
        print("  -v 'D:\\Projects\\ClaudeCode\\topicgenerater:/app' -w /app \\")
        print("  python:3.8-slim python main.py")
        return

    # æŒ‰æ—¶é—´æ’åºï¼Œå–æœ€æ–°çš„
    latest_file = max(output_files)
    print(f"ğŸ“‚ è¯»å–æ–‡ä»¶: {latest_file}\n")

    # åŠ è½½è¯é¢˜
    if not generator.load_topics_from_file(latest_file):
        return

    # ç­›é€‰æ•™è‚²+AIè¯é¢˜
    print("\n[*] æ­£åœ¨ç­›é€‰æµ·å¤–æ•™è‚²+AIè¯é¢˜...")
    parenting_topics = generator.filter_parenting_topics()

    if not parenting_topics:
        print("âŒ æœªæ‰¾åˆ°ç›¸å…³è¯é¢˜")
        print()
        print("ğŸ’¡ å»ºè®®ï¼š")
        print("1. ç¡®ä¿Hacker Newså’ŒYouTubeæ•°æ®è·å–æˆåŠŸ")
        print("2. è¿™äº›å¹³å°åŒ…å«æ›´å¤šæµ·å¤–æ•™è‚²AIè¯é¢˜")
        return

    # è¿‡æ»¤å·²ä½¿ç”¨çš„è¯é¢˜ï¼ˆ30å¤©å†…ï¼‰
    print("\n[*] æ­£åœ¨è¿‡æ»¤å·²ä½¿ç”¨çš„è¯é¢˜ï¼ˆ30å¤©å†…ï¼‰...")
    unused_topics = tracker.filter_unused_topics(parenting_topics, days=30)

    if not unused_topics:
        print("âš ï¸ æ‰€æœ‰ç­›é€‰çš„è¯é¢˜éƒ½åœ¨æœ€è¿‘30å¤©å†…å·²ä½¿ç”¨")
        print()
        print("ğŸ’¡ å»ºè®®ï¼š")
        print("1. è°ƒæ•´dayså‚æ•°æŸ¥çœ‹æ›´æ—©çš„è¯é¢˜")
        print("2. æˆ–è€…ç­‰å¾…æ–°çš„çƒ­ç‚¹è¯é¢˜å‡ºç°")

        # æ˜¾ç¤ºå·²ä½¿ç”¨çš„è¯é¢˜
        print("\nå·²ä½¿ç”¨çš„è¯é¢˜:")
        for topic in parenting_topics[:5]:
            title = topic.get('title', 'æœªçŸ¥')
            print(f"  - {title}")

        return

    print(f"âœ“ åŸå§‹è¯é¢˜æ•°: {len(parenting_topics)}")
    print(f"âœ“ æœªä½¿ç”¨è¯é¢˜æ•°: {len(unused_topics)}")
    print(f"âœ“ è¿‡æ»¤æ‰: {len(parenting_topics) - len(unused_topics)} ä¸ªå·²ä½¿ç”¨è¯é¢˜")

    # é€‰æ‹©æœ€çƒ­é—¨çš„5ä¸ªè¯é¢˜ï¼ˆæˆ–å…¨éƒ¨ï¼Œå¦‚æœä¸è¶³5ä¸ªï¼‰
    print("\n[*] é€‰æ‹©æœ€é€‚åˆçš„è¯é¢˜...")
    selected_topics = unused_topics[:5]

    print(f"\nâœ“ ä¸ºæ‚¨ç”Ÿæˆ {len(selected_topics)} ä¸ªå°çº¢ä¹¦çˆ†æ–‡å†…å®¹\n")

    # ä¸ºæ¯ä¸ªè¯é¢˜ç”Ÿæˆå®Œæ•´å¸–å­
    results = []
    for i, topic in enumerate(selected_topics, 1):
        print(f"\n{'#'*70}")
        print(f"# çˆ†æ–‡ {i}/{len(selected_topics)}")
        print(f"{'#'*70}")

        result = generator.generate_xiaohongshu_post(topic)
        results.append(result)

        # æ ‡è®°è¯é¢˜ä¸ºå·²ä½¿ç”¨
        tracker.mark_topic_used(
            topic['title'],
            metadata={
                'platform': topic.get('platform', ''),
                'category': topic.get('category', ''),
                'url': topic.get('url', ''),
                'generated_at': datetime.now().isoformat()
            }
        )
        print(f"âœ“ å·²æ ‡è®°è¯é¢˜ä¸ºå·²ä½¿ç”¨")

    # ä¿å­˜åˆ°CSVæ–‡ä»¶
    from src.exporter_csv import CSVExporter
    csv_exporter = CSVExporter()

    # å‡†å¤‡CSVæ•°æ®
    csv_data = []
    for result in results:
        # ä¸ºæ¯ä¸ªæ ‡é¢˜åˆ›å»ºä¸€è¡Œæ•°æ®
        for title_info in result['titles']:
            csv_data.append({
                'original_topic': result['topic']['title'],
                'platform': result['topic']['platform'],
                'category': result['topic'].get('category', 'æœªçŸ¥'),
                'title_type': title_info['type'],
                'title': title_info['title'],
                'content': result['content'],
                'image_suggestions': ' | '.join(result['image_suggestions'][:3]),
                'video_suggestions': ' | '.join(result['video_suggestions'][:2]),
                'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            })

    # å¯¼å‡ºCSV
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    csv_file = csv_exporter.export_xiaohongshu_posts(csv_data, f'xiaohongshu_posts_{timestamp}.csv')

    # åŒæ—¶ä¿å­˜Markdownæ–‡ä»¶ï¼ˆå¯é€‰ï¼‰
    md_file = f"output/xiaohongshu_AIæ•™è‚²_{timestamp}.md"
    with open(md_file, 'w', encoding='utf-8') as f:
        f.write("# ğŸ”¥ å°çº¢ä¹¦çˆ†æ–‡åˆé›† - æµ·å¤–æ•™è‚²AIä¸“é¢˜\n\n")
        f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        f.write(f"æ€»ç¯‡æ•°: {len(results)}\n")
        f.write(f"ä¸»é¢˜: æµ·å¤–ä¼ ç»Ÿæ•™è‚²å¦‚ä½•åº”å¯¹AIå˜é©\n\n")
        f.write("="*70 + "\n\n")

        for i, result in enumerate(results, 1):
            f.write(f"## çˆ†æ–‡ {i}: {result['topic']['title']}\n\n")
            f.write(f"**æ¥æº**: {result['topic']['platform']}\n")
            f.write(f"**åˆ†ç±»**: {result['topic'].get('category', 'æœªçŸ¥')}\n\n")

            f.write("### ğŸ¯ æ¨èæ ‡é¢˜\n\n")
            for j, title in enumerate(result['titles'], 1):
                f.write(f"{j}. {title['title']}\n")

            f.write("\n### ğŸ“„ æ­£æ–‡å†…å®¹\n\n")
            f.write(result['content'])
            f.write("\n\n" + "="*70 + "\n\n")

    print(f"\nâœ… CSVå·²ä¿å­˜åˆ°: {csv_file}")
    print(f"âœ… Markdownå·²ä¿å­˜åˆ°: {md_file}")
    print("\nğŸ‰ ç”Ÿæˆå®Œæˆï¼")

    # æ˜¾ç¤ºæ›´æ–°åçš„ç»Ÿè®¡ä¿¡æ¯
    print("\n")
    tracker.print_stats()
    print()
    print("ğŸ’¡ ä½¿ç”¨å»ºè®®ï¼š")
    print("1. é€‰æ‹©æœ€é€‚åˆçš„æ ‡é¢˜")
    print("2. æ ¹æ®å®é™…æƒ…å†µå¾®è°ƒå†…å®¹")
    print("3. æ·»åŠ çœŸå®å›¾ç‰‡ï¼ˆå­©å­å­¦ä¹ åœºæ™¯ã€æ•™è‚²ç›¸å…³ï¼‰")
    print("4. å‘å¸ƒåç§¯æå›å¤è¯„è®ºåŒº")
    print()
    print("ğŸ“Š CSVæ–‡ä»¶å¯ç”¨Excelæ‰“å¼€ï¼Œæ–¹ä¾¿ç¼–è¾‘å’Œç®¡ç†")


if __name__ == '__main__':
    main()
